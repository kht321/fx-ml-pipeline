{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423cf49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evidently\n",
    "evidently.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37798514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\gabjj\\Desktop\\Education\\MITB\\CS611\\project\\fx-ml-pipeline\n",
      "Changed directory to: c:\\Users\\gabjj\\Desktop\\Education\\MITB\\CS611\\project\\fx-ml-pipeline\n",
      "Simulated predictions saved.\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.responses import FileResponse, PlainTextResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "\n",
    "from evidently import Report, Regression, Dataset, DataDefinition\n",
    "from evidently.tests import lte, gte, lt, gt, is_in, not_in, eq, not_eq\n",
    "from evidently.presets import DataDriftPreset, RegressionPreset\n",
    "from evidently.metrics import ValueDrift, DriftedColumnsCount\n",
    "\n",
    "# # Get the AIP token from environment\n",
    "# EVIDENTLY_API_TOKEN = os.getenv(\"EVIDENTLY_AI\")\n",
    "# print(f\"EVIDENTLY_API_TOKEN: {EVIDENTLY_API_TOKEN}\")\n",
    "# ws = CloudWorkspace(token=EVIDENTLY_API_TOKEN, url=\"https://app.evidently.cloud\")\n",
    "\n",
    "# USE CONTAINER PATHS (compose mounts these)\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\", \"data_clean\")\n",
    "REPORTS_DIR = os.getenv(\"REPORTS_DIR\", \"reports\")\n",
    "GOLD = os.path.join(DATA_DIR, \"gold\")\n",
    "GOLD_MKT = os.path.join(DATA_DIR, \"gold\", \"market\", \"features\", \"spx500_features.parquet\")\n",
    "GOLD_NEWS = os.path.join(DATA_DIR, \"gold\", \"news\", \"signals\", \"spx500_trading_signals.parquet\")\n",
    "GOLD_LABELS = os.path.join(DATA_DIR, \"gold\", \"market\", \"labels\", \"spx500_labels_30min.parquet\")   # user_id, target_regression, label\n",
    "PREDS = os.path.join(DATA_DIR, \"predictions\", \"spx500_batch_scores.parquet\")  # user_id, score\n",
    "MODELS = os.path.join(\"models\", \"production\")\n",
    "REPORT_FEATURES_HTML = os.path.join(REPORTS_DIR, \"features_latest_report.html\")\n",
    "REPORT_DRIFT_HTML = os.path.join(REPORTS_DIR, \"features_drift_report.html\")\n",
    "START_TRAIN = \"2023-10-13\"\n",
    "END_TRAIN = \"2025-08-30\"\n",
    "\n",
    "for d in [GOLD_MKT, GOLD_NEWS, GOLD_LABELS, PREDS, REPORT_FEATURES_HTML, REPORT_DRIFT_HTML]:\n",
    "    d = d.replace(\"/\", \"\\\\\")  # for Windows compatibility\n",
    "\n",
    "app = FastAPI(title=\"Evidently 0.6.7 Monitor\")\n",
    "\n",
    "# Ensure the reports dir exists before mounting as static\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "app.mount(\"/reports\", StaticFiles(directory=REPORTS_DIR), name=\"reports\")\n",
    "\n",
    "# Simulate predictions\n",
    "def simulate_predictions():\n",
    "    df_example = pd.read_parquet(GOLD_LABELS.replace(\"/\", \"\\\\\"))\n",
    "    # Perturb the label and rename as score\n",
    "    label = \"target_regression\"\n",
    "    df_example[\"predicted_regression\"] = df_example[label] + 0.1 * (0.5 - np.random.rand(len(df_example)))\n",
    "    df_example[[\"time\", \"predicted_regression\"]].to_parquet(PREDS, index=False)\n",
    "    # Save as parquet for downstream tasks\n",
    "    df_example.to_parquet(PREDS.replace(\"/\", \"\\\\\"), index=False)\n",
    "    print(\"Simulated predictions saved.\")\n",
    "\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "# Change directory to root\n",
    "os.chdir(\"c:\\\\Users\\\\gabjj\\\\Desktop\\\\Education\\\\MITB\\\\CS611\\\\project\\\\fx-ml-pipeline\")\n",
    "print(\"Changed directory to:\", os.getcwd())\n",
    "RUN_SIMULATION = True\n",
    "if RUN_SIMULATION:\n",
    "    simulate_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d9be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_mkt = pd.read_parquet(GOLD_MKT)\n",
    "df_gold_labels = pd.read_parquet(GOLD_LABELS)\n",
    "df_pred = pd.read_parquet(PREDS)\n",
    "df_gold = df_gold_mkt.merge(df_gold_labels[['time', 'target_regression']], on=[\"time\"], how=\"inner\", suffixes=(\"_mkt\", \"_labels\"))\n",
    "df_gold = df_gold.merge(df_pred[['time', 'predicted_regression']], on=[\"time\"], how=\"inner\", suffixes=(\"\", \"_pred\"))\n",
    "\n",
    "with open(os.path.join(MODELS, \"current_features.json\"), \"r\") as f:\n",
    "    current_features = json.load(f)\n",
    "\n",
    "numerical_features = [d for d in df_gold.columns if df_gold[d].dtype in [np.float64, np.int64] and d not in [\"time\", \"predicted_regression\", \"target_regression\"]]\n",
    "categorical_features = [d for d in df_gold.columns if df_gold[d].dtype == object and d not in [\"time\", \"predicted_regression\", \"target_regression\"]]\n",
    "numerical_features = [f for f in numerical_features if f in current_features['features']]\n",
    "categorical_features = [f for f in categorical_features if f in current_features['features']]\n",
    "\n",
    "# Create dataset\n",
    "data_definition = DataDefinition(\n",
    "    regression=[Regression(target=\"target_regression\", prediction=\"predicted_regression\")],\n",
    "    numerical_columns=numerical_features,\n",
    "    categorical_columns=categorical_features\n",
    ")\n",
    "\n",
    "features_train_df = df_gold[(df_gold['time'] >= START_TRAIN) & (df_gold['time'] <= END_TRAIN)][numerical_features + categorical_features + ['time', 'target_regression', 'predicted_regression']]\n",
    "features_oot_df = df_gold[df_gold['time'] > END_TRAIN][numerical_features + categorical_features + ['time', 'target_regression', 'predicted_regression']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c41e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_report() -> str:\n",
    "    if not (os.path.exists(GOLD) and os.path.exists(PREDS)):\n",
    "        raise FileNotFoundError(\"Need gold/features.csv and predictions/batch_scores.csv\")\n",
    "\n",
    "    df_gold_mkt = pd.read_parquet(GOLD_MKT)\n",
    "    df_gold_labels = pd.read_parquet(GOLD_LABELS)\n",
    "    df_pred = pd.read_parquet(PREDS)\n",
    "    df_gold = df_gold_mkt.merge(df_gold_labels[['time', 'target_regression']], on=[\"time\"], how=\"inner\", suffixes=(\"_mkt\", \"_labels\"))\n",
    "    df_gold = df_gold.merge(df_pred[['time', 'predicted_regression']], on=[\"time\"], how=\"inner\", suffixes=(\"\", \"_pred\"))\n",
    "\n",
    "    with open(os.path.join(MODELS, \"current_features.json\"), \"r\") as f:\n",
    "        current_features = json.load(f)['features']\n",
    "\n",
    "    numerical_features = [d for d in df_gold.columns if df_gold[d].dtype in [np.float64, np.int64] and d not in [\"time\", \"predicted_regression\", \"target_regression\"]]\n",
    "    categorical_features = [d for d in df_gold.columns if df_gold[d].dtype == object and d not in [\"time\", \"predicted_regression\", \"target_regression\"]]\n",
    "    numerical_features = [f for f in numerical_features if f in current_features]\n",
    "    categorical_features = [f for f in categorical_features if f in current_features]\n",
    "\n",
    "    # Create dataset\n",
    "    data_definition = DataDefinition(\n",
    "        regression=[Regression(target=\"target_regression\", prediction=\"predicted_regression\")],\n",
    "        numerical_columns=numerical_features,\n",
    "        categorical_columns=categorical_features\n",
    "    )\n",
    "\n",
    "    features_train_df = df_gold[(df_gold['time'] >= START_TRAIN) & (df_gold['time'] <= END_TRAIN)][numerical_features + categorical_features + ['time', 'target_regression', 'predicted_regression']]\n",
    "    features_oot_df = df_gold[df_gold['time'] > END_TRAIN][numerical_features + categorical_features + ['time', 'target_regression', 'predicted_regression']]\n",
    "    reference_dataset = Dataset.from_pandas(features_train_df, data_definition=data_definition)\n",
    "    current_dataset = Dataset.from_pandas(features_oot_df, data_definition=data_definition)\n",
    "\n",
    "    regression_preset = Report(metrics=[\n",
    "        RegressionPreset(\n",
    "            # mae_tests=[lt(0.3)],\n",
    "            # mean_error_tests=[gt(-0.2), lt(0.2)],\n",
    "            # rmse_tests=[lt(0.3)],\n",
    "            # r2score_tests=[gt(0.5)],\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    regression_snapshot_with_reference = regression_preset.run(current_data=current_dataset, reference_data=current_dataset)\n",
    "\n",
    "    # Drift report\n",
    "    value_drift_columns = [ValueDrift(column=col, method=\"psi\", threshold=0.05) for col in numerical_features]\n",
    "    drift_report = Report([\n",
    "        DriftedColumnsCount(\n",
    "            cat_stattest=\"psi\", num_stattest=\"wasserstein\",\n",
    "            per_column_method={\"target_regression\": \"psi\", \"predicted_regression\": \"psi\"}, drift_share=0.8\n",
    "        )\n",
    "    ] + value_drift_columns, include_tests=False)\n",
    "\n",
    "    drift_snapshot = drift_report.run(current_data=current_dataset, reference_data=reference_dataset)\n",
    "\n",
    "    os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "    regression_snapshot_with_reference.save_html(REPORT_FEATURES_HTML)\n",
    "    drift_snapshot.save_html(REPORT_DRIFT_HTML)\n",
    "    \n",
    "    return REPORT_FEATURES_HTML, REPORT_DRIFT_HTML\n",
    "\n",
    "@app.get(\"/ping\", response_class=PlainTextResponse)\n",
    "def ping():\n",
    "    return \"evidently up\\n\"\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "def generate():\n",
    "    try:\n",
    "        path = build_report()\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "    return {\"status\": \"ok\", \"report\": path}\n",
    "\n",
    "@app.get(\"/\")\n",
    "def index():\n",
    "    if not os.path.exists(REPORT_FEATURES_HTML) and not os.path.exists(REPORT_DRIFT_HTML):\n",
    "        try:\n",
    "            build_report()\n",
    "        except Exception as e:\n",
    "            raise HTTPException(status_code=400, detail=f\"Generate failed: {e}\")\n",
    "    return FileResponse(REPORT_FEATURES_HTML, media_type=\"text/html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1086aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
