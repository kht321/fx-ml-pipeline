{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f388a0",
   "metadata": {},
   "source": [
    "# Training Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d509af8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3504fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os, sys\n",
    "import pyspark, pandas as pd, numpy as np\n",
    "import tqdm\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    accuracy_score, precision_recall_fscore_support, roc_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"Transformer models for financial market prediction\"\"\"\n",
    "\n",
    "# filepath: src_clean/training/transformers/config.py\n",
    "\"\"\"Configuration for transformer models\"\"\"\n",
    "\n",
    "class TransformerConfig:\n",
    "    # Model architecture\n",
    "    MODEL_TYPE = \"transformer\"\n",
    "    D_MODEL = 512\n",
    "    N_HEADS = 4\n",
    "    N_LAYERS = 2\n",
    "    D_FF = 2048\n",
    "    DROPOUT = 0.2\n",
    "    \n",
    "    # Training\n",
    "    BATCH_SIZE = 256\n",
    "    LEARNING_RATE = 1e-4\n",
    "    MAX_EPOCHS = 10\n",
    "    EARLY_STOPPING_PATIENCE = 3\n",
    "    SEQUENCE_LENGTH = 50  # Time steps to look back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775f2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Testing GPU with simple tensor operations...\n",
      "GPU test successful! Result shape: torch.Size([1000, 1000])\n",
      "Tensor is on CUDA: True\n",
      "GPU Memory Allocated: 0.02 GB\n",
      "GPU Memory Cached: 0.02 GB\n",
      "GPU Memory Free: 12.86 GB\n",
      "GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "Memory: 12.9 GB\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def monitor_gpu_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "        print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "        print(f\"GPU Memory Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1e9:.2f} GB\")\n",
    "\n",
    "# Test GPU with a simple operation\n",
    "print(\"Testing GPU with simple tensor operations...\")\n",
    "if torch.cuda.is_available():\n",
    "    test_tensor = torch.randn(1000, 1000).cuda()\n",
    "    test_result = torch.mm(test_tensor, test_tensor)\n",
    "    print(f\"GPU test successful! Result shape: {test_result.shape}\")\n",
    "    print(f\"Tensor is on CUDA: {test_result.is_cuda}\")\n",
    "    monitor_gpu_usage()\n",
    "    del test_tensor, test_result\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"CUDA not available\")\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Set memory fraction (optional)\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8)\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50482d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialTransformer(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig, n_features=71):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        # Input embedding for financial features\n",
    "        self.feature_embedding = nn.Linear(\n",
    "            self.n_features, \n",
    "            config.D_MODEL\n",
    "        )\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = nn.Parameter(\n",
    "            torch.randn(config.SEQUENCE_LENGTH, config.D_MODEL)\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.D_MODEL,\n",
    "            nhead=config.N_HEADS,\n",
    "            dim_feedforward=config.D_FF,\n",
    "            dropout=config.DROPOUT,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, config.N_LAYERS)\n",
    "        \n",
    "        # Output head\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(config.D_MODEL, config.D_MODEL // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.DROPOUT),\n",
    "            nn.Linear(config.D_MODEL // 2, 1)  # Binary classification output\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, n_features)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        # Feature embedding\n",
    "        x = self.feature_embedding(x)  # (batch_size, seq_len, d_model)\n",
    "        x = x + self.pos_encoding[:seq_len, :].unsqueeze(0)\n",
    "        transformer_out = self.transformer(x)  # (batch_size, seq_len, d_model)\n",
    "        last_hidden = transformer_out[:, -1, :]  # (batch_size, d_model)\n",
    "        output = self.output_head(last_hidden)  # (batch_size, 1)\n",
    "        return output\n",
    "    \n",
    "class RollingWindowSplit:\n",
    "    def __init__(self, train_window_months=6, val_window_months=1, step_months=1):\n",
    "        self.train_window = pd.DateOffset(months=train_window_months)\n",
    "        self.val_window = pd.DateOffset(months=val_window_months)\n",
    "        self.step = pd.DateOffset(months=step_months)\n",
    "    \n",
    "    def split(self, df, start_date, end_date):\n",
    "        \"\"\"Generate rolling window splits\"\"\"\n",
    "        splits = []\n",
    "        current_date = start_date + self.train_window + self.val_window\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            # Define windows\n",
    "            train_start = current_date - self.train_window - self.val_window\n",
    "            train_end = current_date - self.val_window\n",
    "            val_start = train_end\n",
    "            val_end = current_date\n",
    "            \n",
    "            # Create masks\n",
    "            train_mask = (df['event_timestamp'] >= train_start) & (df['event_timestamp'] < train_end)\n",
    "            val_mask = (df['event_timestamp'] >= val_start) & (df['event_timestamp'] < val_end)\n",
    "            \n",
    "            if train_mask.sum() > 0 and val_mask.sum() > 0:\n",
    "                splits.append({\n",
    "                    'train_idx': df[train_mask].index,\n",
    "                    'val_idx': df[val_mask].index,\n",
    "                    'train_start': train_start,\n",
    "                    'train_end': train_end,\n",
    "                    'val_start': val_start,\n",
    "                    'val_end': val_end\n",
    "                })\n",
    "            \n",
    "            current_date += self.step\n",
    "        \n",
    "        return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8888e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, time\n",
    "def monitor_gpu_realtime():\n",
    "    \"\"\"Monitor GPU usage in real-time\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                gpu_util, mem_used, mem_total = result.stdout.strip().split(', ')\n",
    "                print(f\"GPU Utilization: {gpu_util}%, Memory: {mem_used}MB / {mem_total}MB\")\n",
    "            else:\n",
    "                print(\"Could not get nvidia-smi output\")\n",
    "        except:\n",
    "            print(\"nvidia-smi not available\")\n",
    "    else:\n",
    "        print(\"CUDA not available\")\n",
    "\n",
    "class RollingWindowTransformerTrainer:\n",
    "    def __init__(self, config: TransformerConfig, feature_list=None):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.feature_list = feature_list if feature_list is not None else []\n",
    "        self.final_scaler = None  # Will store the last scaler for test set\n",
    "\n",
    "    def train_rolling_window(self, df, splits, test_df):\n",
    "        \"\"\"Train with rolling window cross-validation\"\"\"\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = self.feature_list if self.feature_list else [col for col in df.columns if col not in [\n",
    "            'event_timestamp', 'target_classification', 'time', 'instrument'\n",
    "        ]]\n",
    "        self.n_features = len(feature_cols)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        for fold, split in enumerate(splits):\n",
    "            print(f\"\\n=== Fold {fold + 1}/{len(splits)} ===\")\n",
    "            print(f\"Train: {split['train_start']} to {split['train_end']}\")\n",
    "            print(f\"Val: {split['val_start']} to {split['val_end']}\")\n",
    "            \n",
    "            # Get data for this fold\n",
    "            train_data = df.loc[split['train_idx']]\n",
    "            val_data = df.loc[split['val_idx']]\n",
    "            \n",
    "            # EXPANDING WINDOW: Fit scaler only on data up to training end\n",
    "            # This simulates real-world scenario where you only know past statistics\n",
    "            historical_data = df[df['event_timestamp'] <= split['train_end']]\n",
    "            fold_scaler = StandardScaler()\n",
    "            fold_scaler.fit(historical_data[feature_cols])\n",
    "            \n",
    "            # Transform with this fold's scaler\n",
    "            train_features = fold_scaler.transform(train_data[feature_cols])\n",
    "            val_features = fold_scaler.transform(val_data[feature_cols])\n",
    "            \n",
    "            # Save the final scaler (from last fold) for test set\n",
    "            if fold == len(splits) - 1:\n",
    "                self.final_scaler = fold_scaler\n",
    "            \n",
    "            # Create datasets\n",
    "            train_dataset = self._create_dataset(\n",
    "                train_features, \n",
    "                train_data['target_classification'].values\n",
    "            )\n",
    "            val_dataset = self._create_dataset(\n",
    "                val_features, \n",
    "                val_data['target_classification'].values\n",
    "            )\n",
    "            \n",
    "            # Create data loaders\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset, \n",
    "                batch_size=self.config.BATCH_SIZE, \n",
    "                shuffle=True,\n",
    "                pin_memory=torch.cuda.is_available(),\n",
    "                num_workers=0\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                val_dataset, \n",
    "                batch_size=self.config.BATCH_SIZE, \n",
    "                shuffle=False,\n",
    "                pin_memory=torch.cuda.is_available(),\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # Train model for this fold\n",
    "            model = self._train_fold(train_loader, val_loader, fold)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_metrics = self._evaluate_model(model, val_loader)\n",
    "            fold_results.append(val_metrics)\n",
    "\n",
    "            # Clean up GPU memory after each fold\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        # Final evaluation on out-of-time test set\n",
    "        test_metrics = self._evaluate_on_test(model, test_df, feature_cols)\n",
    "        \n",
    "        return fold_results, test_metrics\n",
    "    \n",
    "    def _evaluate_on_test(self, model, test_df, feature_cols):\n",
    "        \"\"\"Evaluate on out-of-time test set\"\"\"\n",
    "        if self.final_scaler is None:\n",
    "            raise ValueError(\"No scaler available. Train the model first.\")\n",
    "        \n",
    "        # Use the final scaler (trained on all data up to last training period)\n",
    "        test_features = self.final_scaler.transform(test_df[feature_cols])\n",
    "        \n",
    "        # Create test dataset\n",
    "        test_dataset = self._create_dataset(\n",
    "            test_features,\n",
    "            test_df['target_classification'].values\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        test_metrics = self._evaluate_model(model, test_loader)\n",
    "        return test_metrics\n",
    "    \n",
    "    def _train_fold(self, train_loader, val_loader, fold):\n",
    "        \"\"\"Train model for one fold\"\"\"\n",
    "        model = FinancialTransformer(self.config, n_features=self.n_features).to(self.device)\n",
    "        criterion = nn.BCEWithLogitsLoss()  # For classification\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.config.LEARNING_RATE)\n",
    "        pathlib.Path(\"models/transformers\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Verify model is on GPU\n",
    "        print(f\"Model parameters on CUDA: {next(model.parameters()).is_cuda}\")\n",
    "        if torch.cuda.is_available():\n",
    "            monitor_gpu_usage()\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience = self.config.EARLY_STOPPING_PATIENCE\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.config.MAX_EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device).unsqueeze(1)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x = batch_x.to(self.device)\n",
    "                    batch_y = batch_y.to(self.device).unsqueeze(1)\n",
    "                    with torch.amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                        outputs = model(batch_x)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"Epoch {epoch}: Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "                if torch.cuda.is_available():\n",
    "                    print(f\"  GPU Memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "                    monitor_gpu_realtime()\n",
    "\n",
    "            # Early stopping\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), f'models/transformers/best_model_fold_{fold}.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(torch.load(f'models/transformers/best_model_fold_{fold}.pth'))\n",
    "        return model\n",
    "    \n",
    "    def _create_dataset(self, features, targets):\n",
    "        \"\"\"Create PyTorch dataset with sequences for transformer - OPTIMIZED VERSION\"\"\"\n",
    "        print(f\"Creating dataset with {len(features)} samples, sequence length {self.config.SEQUENCE_LENGTH}\")\n",
    "        \n",
    "        # Check for NaN values and handle them\n",
    "        if np.isnan(features).any():\n",
    "            print(\"Warning: NaN values found in features. Filling with 0.\")\n",
    "            features = np.nan_to_num(features, nan=0.0)\n",
    "        \n",
    "        # Pre-allocate arrays for efficiency\n",
    "        num_sequences = len(features) - self.config.SEQUENCE_LENGTH + 1\n",
    "        sequences = np.zeros((num_sequences, self.config.SEQUENCE_LENGTH, features.shape[1]), dtype=np.float32)\n",
    "        sequence_targets = np.zeros(num_sequences, dtype=np.float32)\n",
    "        \n",
    "        # Create sequences more efficiently\n",
    "        for i in range(num_sequences):\n",
    "            sequences[i] = features[i:i + self.config.SEQUENCE_LENGTH]\n",
    "            sequence_targets[i] = targets[i + self.config.SEQUENCE_LENGTH - 1]\n",
    "        \n",
    "        print(f\"Created {num_sequences} sequences with shape {sequences.shape}\")\n",
    "        \n",
    "        # Convert to tensors efficiently\n",
    "        sequences_tensor = torch.from_numpy(sequences).float()\n",
    "        targets_tensor = torch.from_numpy(sequence_targets).float()\n",
    "        \n",
    "        return torch.utils.data.TensorDataset(sequences_tensor, targets_tensor)\n",
    "        \n",
    "    def _evaluate_model(self, model, data_loader):\n",
    "        \"\"\"Evaluate model and return metrics\"\"\"\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in data_loader:\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device)\n",
    "                \n",
    "                outputs = model(batch_x)\n",
    "                predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "                targets = batch_y.cpu().numpy()\n",
    "                \n",
    "                all_predictions.extend(predictions.flatten())\n",
    "                all_targets.extend(targets.flatten())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        predictions_binary = (np.array(all_predictions) > 0.5).astype(int)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(all_targets, predictions_binary),\n",
    "            'auc': roc_auc_score(all_targets, all_predictions),\n",
    "            'precision': precision_recall_fscore_support(all_targets, predictions_binary, average='weighted')[0],\n",
    "            'recall': precision_recall_fscore_support(all_targets, predictions_binary, average='weighted')[1],\n",
    "            'f1': precision_recall_fscore_support(all_targets, predictions_binary, average='weighted')[2],\n",
    "            'confusion_matrix': confusion_matrix(all_targets, predictions_binary),\n",
    "            'classification_report': classification_report(all_targets, predictions_binary)\n",
    "        }\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca4a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformerTrainer:\n",
    "    def __init__(self, config: TransformerConfig, feature_list=None):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.feature_list = feature_list if feature_list is not None else []\n",
    "        self.scaler = None\n",
    "\n",
    "    def create_time_splits(self, df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "        \"\"\"Create time-based train/val/test splits\"\"\"\n",
    "        df = df.sort_values('event_timestamp').reset_index(drop=True)\n",
    "        \n",
    "        n = len(df)\n",
    "        train_end = int(n * train_ratio)\n",
    "        val_end = int(n * (train_ratio + val_ratio))\n",
    "        \n",
    "        train_df = df.iloc[:train_end].copy()\n",
    "        val_df = df.iloc[train_end:val_end].copy()\n",
    "        test_df = df.iloc[val_end:].copy()\n",
    "        \n",
    "        print(f\"Train: {len(train_df)} samples ({train_df['event_timestamp'].min()} to {train_df['event_timestamp'].max()})\")\n",
    "        print(f\"Val: {len(val_df)} samples ({val_df['event_timestamp'].min()} to {val_df['event_timestamp'].max()})\")\n",
    "        print(f\"Test: {len(test_df)} samples ({test_df['event_timestamp'].min()} to {test_df['event_timestamp'].max()})\")\n",
    "        \n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    def train_single_model(self, train_df, val_df, test_df, holdout_df):\n",
    "        \"\"\"Train a single model with train/val/test + holdout evaluation\"\"\"\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = self.feature_list if self.feature_list else [col for col in train_df.columns if col not in [\n",
    "            'event_timestamp', 'target_classification', 'time', 'instrument'\n",
    "        ]]\n",
    "        self.n_features = len(feature_cols)\n",
    "        \n",
    "        # Fit scaler on training data only\n",
    "        self.scaler = StandardScaler()\n",
    "        train_features = self.scaler.fit_transform(train_df[feature_cols])\n",
    "        val_features = self.scaler.transform(val_df[feature_cols])\n",
    "        test_features = self.scaler.transform(test_df[feature_cols])\n",
    "        holdout_features = self.scaler.transform(holdout_df[feature_cols])\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = self._create_dataset(train_features, train_df['target_classification'].values)\n",
    "        val_dataset = self._create_dataset(val_features, val_df['target_classification'].values)\n",
    "        test_dataset = self._create_dataset(test_features, test_df['target_classification'].values)\n",
    "        holdout_dataset = self._create_dataset(holdout_features, holdout_df['target_classification'].values)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)\n",
    "        holdout_loader = DataLoader(holdout_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        # Train model\n",
    "        model = self._train_model(train_loader, val_loader)\n",
    "        \n",
    "        # Evaluate on all sets\n",
    "        train_metrics = self._evaluate_model(model, train_loader, \"Training\")\n",
    "        val_metrics = self._evaluate_model(model, val_loader, \"Validation\")\n",
    "        test_metrics = self._evaluate_model(model, test_loader, \"Test\")\n",
    "        holdout_metrics = self._evaluate_model(model, holdout_loader, \"Out-of-Time Holdout\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'train_metrics': train_metrics,\n",
    "            'val_metrics': val_metrics,\n",
    "            'test_metrics': test_metrics,\n",
    "            'holdout_metrics': holdout_metrics\n",
    "        }\n",
    "\n",
    "    def _train_model(self, train_loader, val_loader):\n",
    "        \"\"\"Train the transformer model\"\"\"\n",
    "        model = FinancialTransformer(self.config, n_features=self.n_features).to(self.device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.config.LEARNING_RATE)\n",
    "        \n",
    "        print(f\"Model parameters on CUDA: {next(model.parameters()).is_cuda}\")\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience = 5  # Reduced patience since we're not doing CV\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.config.MAX_EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device).unsqueeze(1)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x = batch_x.to(self.device)\n",
    "                    batch_y = batch_y.to(self.device).unsqueeze(1)\n",
    "                    outputs = model(batch_x)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            \n",
    "            # Print progress\n",
    "            if epoch % 2 == 0:  # Print more frequently\n",
    "                print(f\"Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "                if torch.cuda.is_available():\n",
    "                    print(f\"  GPU Memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), 'models/transformers/simpletransformer_best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(torch.load('models/transformers/simpletransformer_best_model.pth'))\n",
    "        return model\n",
    "\n",
    "    def _create_dataset(self, features, targets):\n",
    "        \"\"\"Create PyTorch dataset with sequences\"\"\"\n",
    "        print(f\"Creating dataset with {len(features)} samples, sequence length {self.config.SEQUENCE_LENGTH}\")\n",
    "        \n",
    "        if np.isnan(features).any():\n",
    "            print(\"Warning: NaN values found in features. Filling with 0.\")\n",
    "            features = np.nan_to_num(features, nan=0.0)\n",
    "        \n",
    "        num_sequences = len(features) - self.config.SEQUENCE_LENGTH + 1\n",
    "        sequences = np.zeros((num_sequences, self.config.SEQUENCE_LENGTH, features.shape[1]), dtype=np.float32)\n",
    "        sequence_targets = np.zeros(num_sequences, dtype=np.float32)\n",
    "        \n",
    "        for i in range(num_sequences):\n",
    "            sequences[i] = features[i:i + self.config.SEQUENCE_LENGTH]\n",
    "            sequence_targets[i] = targets[i + self.config.SEQUENCE_LENGTH - 1]\n",
    "        \n",
    "        print(f\"Created {num_sequences} sequences with shape {sequences.shape}\")\n",
    "        \n",
    "        sequences_tensor = torch.from_numpy(sequences).float()\n",
    "        targets_tensor = torch.from_numpy(sequence_targets).float()\n",
    "        \n",
    "        return torch.utils.data.TensorDataset(sequences_tensor, targets_tensor)\n",
    "        \n",
    "    def _evaluate_model(self, model, data_loader, set_name):\n",
    "        \"\"\"Evaluate model and return metrics\"\"\"\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in data_loader:\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                batch_y = batch_y.to(self.device)\n",
    "                \n",
    "                outputs = model(batch_x)\n",
    "                predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "                targets = batch_y.cpu().numpy()\n",
    "                \n",
    "                all_predictions.extend(predictions.flatten())\n",
    "                all_targets.extend(targets.flatten())\n",
    "        \n",
    "        predictions_binary = (np.array(all_predictions) > 0.5).astype(int)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(all_targets, predictions_binary),\n",
    "            'auc': roc_auc_score(all_targets, all_predictions),\n",
    "            'precision': precision_recall_fscore_support(all_targets, predictions_binary, average='weighted')[0],\n",
    "            'recall': precision_recall_fscore_support(all_targets, predictions_binary, average='weighted')[1],\n",
    "            'f1': precision_recall_fscore_support(all_targets, predictions_binary, average='weighted')[2],\n",
    "            'confusion_matrix': confusion_matrix(all_targets, predictions_binary),\n",
    "            'classification_report': classification_report(all_targets, predictions_binary)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{set_name} Metrics:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
    "        print(f\"  F1: {metrics['f1']:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{metrics['confusion_matrix']}\")\n",
    "        print(f\"  Classification Report:\\n{metrics['classification_report']}\")\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71cb240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.getcwd()\n",
    "DATA = os.path.join(ROOT, 'data_clean', 'gold')\n",
    "FEATURES = os.path.join(DATA, 'market', 'features')\n",
    "LABELS = os.path.join(DATA, 'market', 'labels')\n",
    "NEWS = os.path.join(DATA, 'news', 'signals')\n",
    "COMBINED = os.path.join(DATA, 'gold_1', 'features', 'combined_data.parquet')\n",
    "\n",
    "run_combined = False or not os.path.exists(COMBINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52de826",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_combined:\n",
    "    features = pd.read_parquet(os.path.join(FEATURES, 'spx500_features.parquet'))\n",
    "    labels = pd.read_parquet(os.path.join(LABELS, 'spx500_labels_30min.parquet'))\n",
    "    news = pd.read_csv(os.path.join(NEWS, 'sp500_trading_signals.csv'))\n",
    "    features['time'] = pd.to_datetime(features['time'])\n",
    "    news['signal_time'] = pd.to_datetime(news['signal_time'])\n",
    "    if news['signal_time'].dt.tz is None:\n",
    "        news['signal_time'] = news['signal_time'].dt.tz_localize('UTC')\n",
    "\n",
    "    merged_rows = []\n",
    "    tolerance = pd.Timedelta(hours=6)\n",
    "\n",
    "    market_df = features.sort_values('time')\n",
    "    news_df = news.sort_values('signal_time')\n",
    "\n",
    "    news_features = [\n",
    "        'signal_time', 'avg_sentiment', 'signal_strength',\n",
    "        'trading_signal', 'article_count', 'quality_score'\n",
    "    ]\n",
    "    available_news = [c for c in news_features if c in news_df.columns]\n",
    "\n",
    "    for _, market_row in tqdm.tqdm(market_df.iterrows(), total=len(market_df), desc=\"Merging market and news data\"):\n",
    "        market_time = market_row['time']\n",
    "        news_cutoff = market_time - tolerance\n",
    "        eligible_news = news_df[\n",
    "            (news_df['signal_time'] <= market_time) &\n",
    "            (news_df['signal_time'] >= news_cutoff)\n",
    "        ]\n",
    "\n",
    "        merged_row = market_row.to_dict()\n",
    "\n",
    "        if not eligible_news.empty:\n",
    "            latest_news = eligible_news.iloc[-1]\n",
    "            for col in available_news:\n",
    "                if col != 'signal_time':\n",
    "                    merged_row[f'news_{col}'] = latest_news[col]\n",
    "            news_age_minutes = (market_time - latest_news['signal_time']).total_seconds() / 60\n",
    "            merged_row['news_age_minutes'] = news_age_minutes\n",
    "            merged_row['news_available'] = 1\n",
    "        else:\n",
    "            for col in available_news:\n",
    "                if col != 'signal_time':\n",
    "                    merged_row[f'news_{col}'] = 0.0\n",
    "            merged_row['news_age_minutes'] = np.nan\n",
    "            merged_row['news_available'] = 0\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    combined_df = pd.DataFrame(merged_rows)\n",
    "\n",
    "    # Create a folder gold_1 if it doesn't exist\n",
    "    pathlib.Path(\"data_clean/gold/gold_1/features\").mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(\"data_clean/gold/gold_1/labels\").mkdir(parents=True, exist_ok=True)\n",
    "    combined_df.to_parquet(\"data_clean/gold/gold_1/features/combined_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045c3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1435407 samples\n",
      "Test data: 23213 samples\n",
      "Date range - Train: 2020-10-13 16:15:00+00:00 to 2024-12-31 21:59:00+00:00\n",
      "Date range - Test: 2025-01-01 23:00:00+00:00 to 2025-01-27 13:58:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Load the data (if not already loaded)\n",
    "if not 'combined_df' in locals():\n",
    "    combined_df = pd.read_parquet(COMBINED)\n",
    "\n",
    "if not 'labels' in locals():\n",
    "    labels = pd.read_parquet(os.path.join(LABELS, 'spx500_labels_30min.parquet'))\n",
    "config = TransformerConfig()\n",
    "gold_1_features = combined_df.drop(columns=['instrument', 'time'], axis=1)\n",
    "gold_1_full = gold_1_features.merge(labels[['event_timestamp', 'target_classification']], on='event_timestamp', how='inner')\n",
    "gold_1_full['event_timestamp'] = pd.to_datetime(gold_1_full['event_timestamp'])\n",
    "gold_1_full = gold_1_full.sort_values('event_timestamp').reset_index(drop=True)\n",
    "\n",
    "# Define split dates\n",
    "holdout_date = pd.Timestamp('2025-01-01', tz='UTC')\n",
    "val_split_date = pd.Timestamp('2024-10-01', tz='UTC')\n",
    "\n",
    "# Create training data (before holdout) and test data (after holdout)\n",
    "training_data = gold_1_full[gold_1_full['event_timestamp'] < holdout_date].copy()\n",
    "test_data = gold_1_full[gold_1_full['event_timestamp'] >= holdout_date].copy()\n",
    "\n",
    "print(f\"Training data: {len(training_data)} samples\")\n",
    "print(f\"Test data: {len(test_data)} samples\")\n",
    "print(f\"Date range - Train: {training_data['event_timestamp'].min()} to {training_data['event_timestamp'].max()}\")\n",
    "print(f\"Date range - Test: {test_data['event_timestamp'].min()} to {test_data['event_timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70dbe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 44 rolling window splits\n"
     ]
    }
   ],
   "source": [
    "# Use rolling window for training data only (before holdout)\n",
    "rolling_splitter = RollingWindowSplit(train_window_months=6, val_window_months=1)\n",
    "training_data = gold_1_full[gold_1_full['event_timestamp'] < holdout_date]\n",
    "splits = rolling_splitter.split(\n",
    "    training_data, \n",
    "    start_date=training_data['event_timestamp'].min(),\n",
    "    end_date=training_data['event_timestamp'].max()\n",
    ")\n",
    "print(f\"Generated {len(splits)} rolling window splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76cbe795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the trainer\n",
    "# trainer = RollingWindowTransformerTrainer(config)\n",
    "\n",
    "# # Run training with rolling window cross-validation\n",
    "# print(\"Starting transformer training with rolling window cross-validation...\")\n",
    "\n",
    "# try:\n",
    "#     fold_results, test_metrics = trainer.train_rolling_window(\n",
    "#         df=training_data,\n",
    "#         splits=splits,\n",
    "#         test_df=test_data\n",
    "#     )\n",
    "    \n",
    "#     # Print results\n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"TRAINING COMPLETE\")\n",
    "#     print(\"=\"*50)\n",
    "    \n",
    "#     # Fold results\n",
    "#     print(\"\\nCross-validation results:\")\n",
    "#     for i, metrics in enumerate(fold_results):\n",
    "#         print(f\"Fold {i+1}: Accuracy: {metrics['accuracy']:.4f}, AUC: {metrics['auc']:.4f}, F1: {metrics['f1']:.4f}\")\n",
    "    \n",
    "#     try:\n",
    "#         # Average CV performance\n",
    "#         avg_metrics = {\n",
    "#             'accuracy': np.mean([m['accuracy'] for m in fold_results]),\n",
    "#             'auc': np.mean([m['auc'] for m in fold_results]),\n",
    "#             'f1': np.mean([m['f1'] for m in fold_results]),\n",
    "#             'precision': np.mean([m['precision'] for m in fold_results]),\n",
    "#             'recall': np.mean([m['recall'] for m in fold_results]),\n",
    "#             'confusion_matrix': np.mean([m['confusion_matrix'] for m in fold_results]),\n",
    "#             'classification_report': np.mean([m['classification_report'] for m in fold_results]),\n",
    "#         }\n",
    "        \n",
    "#         print(f\"\\nAverage CV Performance:\")\n",
    "#         for metric, value in avg_metrics.items():\n",
    "#             print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "#         # Test set performance\n",
    "#         print(f\"\\nOut-of-time Test Performance:\")\n",
    "#         for metric, value in test_metrics.items():\n",
    "#             print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error calculating average metrics: {e}\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"Training failed with error: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84527dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting single transformer model training...\n",
      "==================================================\n",
      "Train: 1004784 samples (2020-10-13 16:15:00+00:00 to 2023-09-14 11:00:00+00:00)\n",
      "Val: 215311 samples (2023-09-14 11:01:00+00:00 to 2024-05-10 17:12:00+00:00)\n",
      "Test: 215312 samples (2024-05-10 17:13:00+00:00 to 2024-12-31 21:59:00+00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabjj\\anaconda3\\envs\\cs611\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1144: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\gabjj\\anaconda3\\envs\\cs611\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1149: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\gabjj\\anaconda3\\envs\\cs611\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1169: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with 1004784 samples, sequence length 50\n",
      "Warning: NaN values found in features. Filling with 0.\n",
      "Created 1004735 sequences with shape (1004735, 50, 71)\n",
      "Creating dataset with 215311 samples, sequence length 50\n",
      "Warning: NaN values found in features. Filling with 0.\n",
      "Created 215262 sequences with shape (215262, 50, 71)\n",
      "Creating dataset with 215312 samples, sequence length 50\n",
      "Warning: NaN values found in features. Filling with 0.\n",
      "Created 215263 sequences with shape (215263, 50, 71)\n",
      "Creating dataset with 23213 samples, sequence length 50\n",
      "Warning: NaN values found in features. Filling with 0.\n",
      "Created 23164 sequences with shape (23164, 50, 71)\n",
      "Model parameters on CUDA: True\n",
      "Epoch 0: Train Loss: 0.6928, Val Loss: 0.6928\n",
      "  GPU Memory: 0.13 GB\n",
      "Epoch 2: Train Loss: 0.6924, Val Loss: 0.6928\n",
      "  GPU Memory: 0.13 GB\n",
      "Epoch 4: Train Loss: 0.6923, Val Loss: 0.6928\n",
      "  GPU Memory: 0.13 GB\n",
      "Epoch 6: Train Loss: 0.6924, Val Loss: 0.6929\n",
      "  GPU Memory: 0.13 GB\n",
      "Early stopping at epoch 6\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.5171\n",
      "  AUC: 0.5217\n",
      "  F1: 0.4958\n",
      "  Confusion Matrix:\n",
      "[[154176 343347]\n",
      " [141791 365421]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.31      0.39    497523\n",
      "         1.0       0.52      0.72      0.60    507212\n",
      "\n",
      "    accuracy                           0.52   1004735\n",
      "   macro avg       0.52      0.52      0.49   1004735\n",
      "weighted avg       0.52      0.52      0.50   1004735\n",
      "\n",
      "\n",
      "Validation Metrics:\n",
      "  Accuracy: 0.5180\n",
      "  AUC: 0.5176\n",
      "  F1: 0.4805\n",
      "  Confusion Matrix:\n",
      "[[26089 79936]\n",
      " [23829 85408]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.25      0.33    106025\n",
      "         1.0       0.52      0.78      0.62    109237\n",
      "\n",
      "    accuracy                           0.52    215262\n",
      "   macro avg       0.52      0.51      0.48    215262\n",
      "weighted avg       0.52      0.52      0.48    215262\n",
      "\n",
      "\n",
      "Test Metrics:\n",
      "  Accuracy: 0.5134\n",
      "  AUC: 0.5090\n",
      "  F1: 0.3719\n",
      "  Confusion Matrix:\n",
      "[[  2976 101591]\n",
      " [  3158 107538]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.03      0.05    104567\n",
      "         1.0       0.51      0.97      0.67    110696\n",
      "\n",
      "    accuracy                           0.51    215263\n",
      "   macro avg       0.50      0.50      0.36    215263\n",
      "weighted avg       0.50      0.51      0.37    215263\n",
      "\n",
      "\n",
      "Out-of-Time Holdout Metrics:\n",
      "  Accuracy: 0.5186\n",
      "  AUC: 0.5164\n",
      "  F1: 0.3637\n",
      "  Confusion Matrix:\n",
      "[[  153 11068]\n",
      " [   82 11861]]\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.01      0.03     11221\n",
      "         1.0       0.52      0.99      0.68     11943\n",
      "\n",
      "    accuracy                           0.52     23164\n",
      "   macro avg       0.58      0.50      0.35     23164\n",
      "weighted avg       0.58      0.52      0.36     23164\n",
      "\n",
      "\n",
      "==================================================\n",
      "TRAINING COMPLETE\n",
      "==================================================\n",
      "\n",
      "Final Results Summary:\n",
      "Training Accuracy: 0.5171\n",
      "Validation Accuracy: 0.5180\n",
      "Test Accuracy: 0.5134\n",
      "Out-of-Time Holdout Accuracy: 0.5186\n",
      "\n",
      "AUC Scores:\n",
      "Training AUC: 0.5217\n",
      "Validation AUC: 0.5176\n",
      "Test AUC: 0.5090\n",
      "Out-of-Time Holdout AUC: 0.5164\n"
     ]
    }
   ],
   "source": [
    "# Initialize the simple trainer\n",
    "trainer = SimpleTransformerTrainer(config)\n",
    "\n",
    "print(\"Starting single transformer model training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Create train/val/test splits within your training period\n",
    "    train_df, val_df, test_df = trainer.create_time_splits(training_data)\n",
    "    \n",
    "    # Train single model and evaluate on all sets including holdout\n",
    "    results = trainer.train_single_model(train_df, val_df, test_df, test_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nFinal Results Summary:\")\n",
    "    print(f\"Training Accuracy: {results['train_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"Validation Accuracy: {results['val_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"Test Accuracy: {results['test_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"Out-of-Time Holdout Accuracy: {results['holdout_metrics']['accuracy']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nAUC Scores:\")\n",
    "    print(f\"Training AUC: {results['train_metrics']['auc']:.4f}\")\n",
    "    print(f\"Validation AUC: {results['val_metrics']['auc']:.4f}\")\n",
    "    print(f\"Test AUC: {results['test_metrics']['auc']:.4f}\")\n",
    "    print(f\"Out-of-Time Holdout AUC: {results['holdout_metrics']['auc']:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba58715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# print out model metrics report\n",
    "print(\"\\nModel training and evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
